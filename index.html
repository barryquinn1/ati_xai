<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>FIN7030: Algorithmic trading and investment</title>
    <meta charset="utf-8" />
    <meta name="author" content="Barry Quinn" />
    <meta name="date" content="2022-03-29" />
    <script src="libs/header-attrs-2.11/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/panelset-0.2.6/panelset.css" rel="stylesheet" />
    <script src="libs/panelset-0.2.6/panelset.js"></script>
    <link rel="stylesheet" href="fonts.css" type="text/css" />
    <link rel="stylesheet" href="mycssblend.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# FIN7030: Algorithmic trading and investment
## Explainable financial machine learning
### Barry Quinn
### 2022-03-29

---




layout: true
  
&lt;div class="my-footer"&gt;&lt;span&gt;quinference.com&lt;/span&gt;&lt;/div&gt;

---
class:inverse, middle
# Outline
.large[
- Can machines learning finance? 
- Importance of interpretation in finance
- Responsible AI and explaining *black-box-ness*
]

---
class: middle

# What is machine learning?

.acid[
- Machine learning is the study of computer algorithms that allow computer programs to automatically improve through experience.”- Mitchell (1997)

- This encompasses much of the traditional **Quant** investment research and more broadly of the field of statistics more broadly.
]

---
class: middle

## Is machine learning just applied computational statistics?

![](img/sandserif.png){width=50%}



.footnote[Mitchell, T. M. (1997). Machine Learning, McGraw-Hill International Editions (McGraw-Hill).]

---
class: middle

## Is financial machine learning just applied computational statistics?

- NO

- [Gu, Kelly and Xiu (2020)](https://dx.doi.org/10.1093/rfs/hhaa009) provide the best FML definition in 4 points:

.blockquote [
1. The definition of *machine learning* is [inchoate](https://www.merriam-webster.com/dictionary/inchoate) and is often context specific.  

They use the term to describe:

2. a diverse collection of high-dimensional models for statistical prediction, combined with
3. so-called *regularisation* methods for model selection and mitigation of overfit, and
4. efficient algorithms for searching among a vast number of potential model specifications.
]

---
class: middle

## [Gu, Kelly and Xiu (2020)](https://dx.doi.org/10.1093/rfs/hhaa009)  definition explained

1. The field ML is often view as marketing hype, but this usually stems from confusion as the field is evolving fast and people's basic understandings are still developing.

2. Historical practice has been *small*, simple, linear models with few predictors (or feature in ML language). ML brings an open-mindedness for statistical representation that are richly parameterised and often nonlinear, these models are not new to statistics, but ML *specialises* at this end of the modelling spectrum.

3. Model complexity without control leads to poor out-of-sample performance. *Regularisation* is a blanket term for constraining the size of the model, to achieve a **Goldlicks** model.
  - *Goldlicks* models are **large enough** so that it can reliably identify the true (potentially complex) predictive relationships in the data, but not so flexible that it overfits and suffers out-of-sample.
  
4. Model optimisation innovations are perhaps the clearest *differentiator* from traditional statistics, where routines such as **stochastic gradient descent** dramatically speed up optimal model selection when dataset are *Big*. 

---
class: middle

# Finance is different compared to traditional ML research

- ML suceeds where there is a high signal to noise ratio: **how much predictability exists within a system**
  - I can easily find 1,000,00 random photos online and you would easily be able to identify cat photos from blur or background images with 100% accuracy.

- Financial return prediction is a *small data problem* because it depends on how many T independent observations you have in the following equation, not N.  In returns data the only way we can increase the dataset is to wait for the passage of time

`$$FinancialReturns_t=\sum_{i=1}^N \beta_i x_{i,t-1} \dots t=1,\dots, T$$`
- [Dhar (2015)](https://dx.doi.org/10.1089/big.2015.28999.vda) suggests when humans vs machine in financial decision-making is consider .blockquote[a robot should be considered seriously in situations where there is sufficient data which it can learn]


---
class: middle

# Finance is different compared to traditional ML research

- In finance the signal-to-noise ratio in returns is weak. Typically a single stock with have an expected return around 5% per year above cash and a volatility of nearly 40% per year ([Israel, Kelly, Moskowitz (2020)](img/AQR-Alternative-Thin.pdf))

 - An interesting feature of expected returns is their predictability increases with forecast horizon (monthly returns have more signal than daily for example) [Cochrane 2009](https://www.johnhcochrane.com/asset-pricing)

- Financial market predictability evolves over time further confounding low signal-to-noise ratios, making finance much more complex than other ML research areas  - **cats do not morph into dogs when the algorithms gets good at recognising cats** - Israel, Kelly, Moskowitz (2022)

- Unstructured (or in finance language alternative) such as social media, digital news provide godo potential.  Again the problem is small T as most social media dataset are limited to 10 years of data, limiting backtesting and thus meaningful investment strategy formation.

---
class: middle

## Finance needs interpretability

- Some machine learning models are proverbial black boxes
- It can be extremely challenging to draw meaningful interpretations of underlying mechanisms from machine learning models ([Ghorbani et al., 2019](https://arxiv.org/abs/1710.10547)). 

- Yet, the ability to understand the inner workings of one’s model is a basic requirement in most **investment management applications**

### Predictability/interpretability frontier in finance

- There is a trade-off similar to the risk-return trade-off in finance

- So, while asset managers prefer a model with more predictability to less, their fiduciary duty of understanding and communicating the risks in their clients’ portfolios leads them to also prefer more interpretable models. 

- In the end, choosing a point on the predictability/interpretability frontier is a ultimately a business decision of the asset manager.

- This fiduciary duty is a key *responsbility* of finanical professionals.

---
class: middle
# Responsible AI
.heat[
- AI now permeates most parts of our everyday lives
- PwC estimate that AI could contribute [$15.7 trillion](https://www.pwc.com/gx/en/issues/data-and-analytics/artificial-intelligence/what-is-responsible-ai.html) to the global economy by 2030.
- This would be mostly as a result of productivity gains and increased consumer demand driven by AI-enhanced products and services. 
- With such great potential comes great risk
- ['Right to Explanation` GDPR law for machine learning algorithms](https://ojs.aaai.org/index.php/aimagazine/article/view/2741)
]
---
class: middle
# Principles of Responsible AI
- Due to the ubiquitous nature of AI in public and private sector corporations, many organisations have published guidelines to tackle issues related to potential AI threats to both the individual and society as a whole. 
.blockquote[
These principles can be summarised into 6 categories:
1. Fairness
2. Ethics
3. Privacy
4. Accountability
5. Transparency
6. Security and safety
]
---
class: middle
# *black-box-ness* critiques

- The last few years has witness the rise of opaque decision systems such as Deep Neural Networks (DNNs)

- The empirical success of Deep Learning (DL) models such as DNNs stems from a combination of efficient learning algorithms and their huge parametric space. 
- The latter space comprises hundreds of layers and millions of parameters, which makes DNNs be considered as complex black-box models. 
- The opposite of *black-box-ness* is transparency, i.e., the search for a direct understanding of the mechanism by which a model works.
- Explanations supporting the output of a model are crucial, especially in finance.

---
class: middle
# Can interpretability improve FML performance?

.large[
- The [cognitive psychology of explanation](https://www.darpa.mil/program/explainable-artificial-intelligence) tells us humans are reticent to adopt techniques that are not directly interpretable, tractable, and trustworthy.
- One reason is that explaining is about convincing an audience with logic-based formulations of (counter) arguments.
- It is customary to think that by focusing solely on performance, the systems will be increasingly opaque. 
- This is true in the sense that there is a trade-off between the performance of a model and its transparency. 
- However, an improvement in the understanding of a system can lead to the correction of its deficiencies. 
]

---
class: middle
# Can interpretability improve FML performance?

.large[
- Adding interpretability as an additional design driver to FML models can improve its implementability for 3 reasons:

1. .heatinline[Interpretability helps ensure impartiality in decision-making, i.e. to detect, and consequently, correct from bias in the training dataset.]

2. .saltinline[Interpretability facilitates the provision of robustness by highlighting potential adversarial perturbations that could change the prediction.]

3. .acidinline[Interpretability can act as an insurance that only meaningful variables infer the output, i.e., guaranteeing that an underlying truthful causality exists in the model reasoning.]
]

---
class: middle
# eXplainable AI (XAI)
.acidinline[
- eXplainable AI (XAI) proposes creating a suite of ML techniques that:
1. produce more explainable models while maintaining a high level of learning performance (e.g., prediction accuracy), and 
2. enable humans to understand, appropriately trust, and effectively manage the emerging generation of artificially intelligent partners. 
- XAI also draws insights from the Social Sciences and considers the psychology of explanation.
]

---
class: middle
# Outbreak in XAI literature
.pull-left[
![](img/XAI_lit_evolve.jpg)
]
.pull-right[
.saltinline[
- Barredo Arrieta et. al, (2020) argue model explainability is among the most crucial aspects to be ensured within this methodological framework of responsible AI
]
]

---
class: middle
## XAI: Who? and Why?
![](img/XAItargets.jpg)

---
class: middle
## Post-hoc explainability techniques for machine learning models
.pull-left[
![](img/post-hoc-ML-explainers.jpg)
]
.pull-right[
- Post-hoc explainability techniques can be further differentiated into model-agnostic and model- specific techniques. 
- The former being more general than the latter. 
]
---
class: middle

## Progress in Explainable FML

- First, researchers are making progress in improving how humans interpret machine learning models (Zhang et al., 2018; Horel and Giesecke, 2019).
- Second, and perhaps more interestingly, structural modeling approaches can embed machine learning techniques, which make efficient use of the data and enhances discovery, within an overarching theoretical model that provides interpretation and intuition.

- Papers that combine economic theory and machine learning are proving successful in tackling the low signal-to-noise ratio.

- Academic example: Kelly, B., Pruitt, S., and Su, Y. (2019). “Characteristics Are Covariances: A Unified Model of Risk and Return,” Journal of Financial Economics 134(3), 501–524.
- Industry example: Gu, S., Kelly, B. T., and Xiu, D. (2019). Autoencoder Asset Pricing Models, Available at https://www.aqr.com/Insights/Research/Working-Paper/Autoencoder-Asset-Pricing-Models


---
class: inverse
# Summary

.acid[
- In computer-age statistical inference, p-values are found lacking.
- The new AI revolution is in the development of responsible AI tools, with XAI being a central theme for responsibility
- We have introduced a number of post-hoc methods to explain the results of black-box FML models.
- One exciting new field that we have not covered is *white-box*  techniques for deep neural networks which extract meaning similar to the use of linear regression models are using in finance.
- For example see Dixon et al. (2020) Chapter 5 on Interpretability.
]
---
class:middle
# References

.small[

[Barredo Arrieta, Alejandro, Natalia Díaz-Rodríguez, Javier Del Ser, Adrien Bennetot, Siham Tabik, Alberto Barbado, Salvador Garcia, et al. 2020. “Explainable Artificial Intelligence (XAI): Concepts, Taxonomies, Opportunities and Challenges toward Responsible AI.” An International Journal on Information Fusion 58 (June): 82–115.](https://www.sciencedirect.com/science/article/pii/S1566253519308103#bbib0385)

[Goodman, Bryce, and Seth Flaxman. 2017. “European Union Regulations on Algorithmic Decision-Making and a ‘Right to Explanation.’” AI Magazine 38 (3): 50–57.](https://ojs.aaai.org/index.php/aimagazine/article/view/2741)

[Jafar A Khan, Stefan Van Aelst &amp; Ruben H Zamar (2007) Robust Linear Model Selection Based on Least Angle Regression, Journal of the American Statistical Association, 102:480, 1289-1299,](https://www.tandfonline.com/doi/abs/10.1198/016214507000000950)

[Gu, Shihao, Bryan Kelly, and Dacheng Xiu. 2020. “Empirical Asset Pricing via Machine Learning.” The Review of Financial Studies, Working Paper Series, , February.](https://doi.org/10.1093/rfs/hhaa009)

[Goldstein, Alex, Adam Kapelner, Justin Bleich, and Emil Pitkin. 2015. “Peeking Inside the Black Box: Visualizing Statistical Learning With Plots of Individual Conditional Expectation.” Journal of Computational and Graphical Statistics: A Joint Publication of American Statistical Association, Institute of Mathematical Statistics, Interface Foundation of North America 24 (1): 44–65.](http://dx.doi.org/10.1080/10618600.2014.907095)

[Štrumbelj, Erik, and Igor Kononenko. 2014. “Explaining Prediction Models and Individual Predictions with Feature Contributions.” Knowledge and Information Systems 41 (3): 647–65.](https://link.springer.com/article/10.1007/s10115-013-0679-x)

Harvey, Campbell R., Presidential Address: The Scientific Outlook in Financial Economics (July 17, 2017). Duke I&amp;E Research Paper No. 2017-05, Available at SSRN: https://ssrn.com/abstract=2893930 or http://dx.doi.org/10.2139/ssrn.2893930

[Dimopoulos, Yannis, Paul Bourret, and Sovan Lek. 1995. “Use of Some Sensitivity Criteria for Choosing Networks with Good Generalization Ability.” Neural Processing Letters 2 (6): 1–4.](https://link.springer.com/article/10.1007/BF02309007)

Interpretability (Chapter 5) in Machine Learning in Finance : From Theory to Practice (2020) by Matthew F. Dixon,Igor Halperin,and Paul Bilokon [QUB link](https://ebookcentral-proquest-com.queens.ezp1.qub.ac.uk/lib/qub/reader.action?docID=6247297&amp;ppg=189)

Molnar,  C.  (2019):  " Interpretable  Machine  Learning:  A  Guide  for  Making   Black-  Box  Models  Explainable  (Links to an external site.) ."  [QUB link](https://enco r e.qub.ac.uk/iii/encore/record/C__Rb2183044)

[Apley, Daniel W., and Jingyu Zhu. 2020. “Visualizing the Effects of Predictor Variables in Black Box Supervised Learning Models.” Journal of the Royal Statistical Society. Series B, Statistical Methodology 82 (4): 1059–86.](http://dx.doi.org/10.1111/rssb.12377)
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": true,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
(function(time) {
  var d2 = function(number) {
    return ('0' + number).slice(-2); // left-pad 0 to minutes/seconds
  },

  time_format = function(total) {
    var secs = Math.abs(total) / 1000;
    var h = Math.floor(secs / 3600);
    var m = Math.floor(secs % 3600 / 60);
    var s = Math.round(secs % 60);
    var res = d2(m) + ':' + d2(s);
    if (h > 0) res = h + ':' + res;
    return res;  // [hh:]mm:ss
  },

  slide_number_div = function(i) {
    return document.getElementsByClassName('remark-slide-number').item(i);
  },

  current_page_number = function(i) {
    return slide_number_div(i).firstChild.textContent;  // text "i / N"
  };

  var timer = document.createElement('span'); timer.id = 'slide-time-left';
  var time_left = time, k = slideshow.getCurrentSlideIndex(),
      last_page_number = current_page_number(k);

  setInterval(function() {
    time_left = time_left - 1000;
    timer.innerHTML = ' ' + time_format(time_left);
    if (time_left < 0) timer.style.color = 'red';
  }, 1000);

  slide_number_div(k).appendChild(timer);

  slideshow.on('showSlide', function(slide) {
    var i = slide.getSlideIndex(), n = current_page_number(i);
    // reset timer when a new slide is shown and the page number is changed
    if (last_page_number !== n) {
      time_left = time; last_page_number = n;
      timer.innerHTML = ' ' + time_format(time); timer.style.color = null;
    }
    slide_number_div(i).appendChild(timer);
  });
})(120000);
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
